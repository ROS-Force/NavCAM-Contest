Param: BRIEF/Bytes = "32"                                  [Bytes is a length of descriptor in bytes. It can be equal 16, 32 or 64 bytes.]
Param: BRISK/Octaves = "3"                                 [Detection octaves. Use 0 to do single scale.]
Param: BRISK/PatternScale = "1"                            [Apply this scale to the pattern used for sampling the neighbourhood of a keypoint.]
Param: BRISK/Thresh = "30"                                 [FAST/AGAST detection threshold score.]
Param: FAST/CV = "0"                                       [Enable FastCV implementation if non-zero (and RTAB-Map is built with FastCV support). Values should be 9 and 10.]
Param: FAST/Gpu = "false"                                  [GPU-FAST: Use GPU version of FAST. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
Param: FAST/GpuKeypointsRatio = "0.05"                     [Used with FAST GPU.]
Param: FAST/GridCols = "0"                                 [Grid cols (0 to disable). Adapts the detector to partition the source image into a grid and detect points in each cell.]
Param: FAST/GridRows = "0"                                 [Grid rows (0 to disable). Adapts the detector to partition the source image into a grid and detect points in each cell.]
Param: FAST/MaxThreshold = "200"                           [Maximum threshold. Used only when FAST/GridRows and FAST/GridCols are set.]
Param: FAST/MinThreshold = "7"                             [Minimum threshold. Used only when FAST/GridRows and FAST/GridCols are set.]
Param: FAST/NonmaxSuppression = "true"                     [If true, non-maximum suppression is applied to detected corners (keypoints).]
Param: FAST/Threshold = "20"                               [Threshold on difference between intensity of the central pixel and pixels of a circle around this pixel.]
Param: FREAK/NOctaves = "4"                                [Number of octaves covered by the detected keypoints.]
Param: FREAK/OrientationNormalized = "true"                [Enable orientation normalization.]
Param: FREAK/PatternScale = "22"                           [Scaling of the description pattern.]
Param: FREAK/ScaleNormalized = "true"                      [Enable scale normalization.]
Param: GFTT/BlockSize = "3"                                []
Param: GFTT/K = "0.04"                                     []
Param: GFTT/MinDistance = "3"                              []
Param: GFTT/QualityLevel = "0.001"                         []
Param: GFTT/UseHarrisDetector = "false"                    []
Param: GMS/ThresholdFactor = "6.0"                         [The higher, the less matches.]
Param: GMS/WithRotation = "false"                          [Take rotation transformation into account.]
Param: GMS/WithScale = "false"                             [Take scale transformation into account.]
Param: GTSAM/Optimizer = "1"                               [0=Levenberg 1=GaussNewton 2=Dogleg]
Param: KAZE/Diffusivity = "1"                              [Diffusivity type: 0=DIFF_PM_G1, 1=DIFF_PM_G2, 2=DIFF_WEICKERT or 3=DIFF_CHARBONNIER.]
Param: KAZE/Extended = "false"                             [Set to enable extraction of extended (128-byte) descriptor.]
Param: KAZE/NOctaveLayers = "4"                            [Default number of sublevels per scale level.]
Param: KAZE/NOctaves = "4"                                 [Maximum octave evolution of the image.]
Param: KAZE/Threshold = "0.001"                            [Detector response threshold to accept keypoint.]
Param: KAZE/Upright = "false"                              [Set to enable use of upright descriptors (non rotation-invariant).]
Param: ORB/EdgeThreshold = "19"                            [This is size of the border where the features are not detected. It should roughly match the patchSize parameter.]
Param: ORB/FirstLevel = "0"                                [It should be 0 in the current implementation.]
Param: ORB/Gpu = "false"                                   [GPU-ORB: Use GPU version of ORB. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
Param: ORB/NLevels = "3"                                   [The number of pyramid levels. The smallest level will have linear size equal to input_image_linear_size/pow(scaleFactor, nlevels).]
Param: ORB/PatchSize = "31"                                [size of the patch used by the oriented BRIEF descriptor. Of course, on smaller pyramid layers the perceived image area covered by a feature will be larger.]
Param: ORB/ScaleFactor = "2"                               [Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor will mean that to cover certain scale range you will need more pyramid levels and so the speed will suffer.]
Param: ORB/ScoreType = "0"                                 [The default HARRIS_SCORE=0 means that Harris algorithm is used to rank features (the score is written to KeyPoint::score and is used to retain best nfeatures features); FAST_SCORE=1 is alternative value of the parameter that produces slightly less stable keypoints, but it is a little faster to compute.]
Param: ORB/WTA_K = "2"                                     [The number of points that produce each element of the oriented BRIEF descriptor. The default value 2 means the BRIEF where we take a random point pair and compare their brightnesses, so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3 random points (of course, those point coordinates are random, but they are generated from the pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such output will occupy 2 bits, and therefore it will need a special variant of Hamming distance, denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).]
Param: Odom/AlignWithGround = "false"                      [Align odometry with the ground on initialization.]
Param: Odom/FillInfoData = "true"                          [Fill info with data (inliers/outliers features).]
Param: Odom/FilteringStrategy = "0"                        [0=No filtering 1=Kalman filtering 2=Particle filtering. This filter is used to smooth the odometry output.]
Param: Odom/GuessMotion = "true"                           [Guess next transformation from the last motion computed.]
Param: Odom/GuessSmoothingDelay = "0"                      [Guess smoothing delay (s). Estimated velocity is averaged based on last transforms up to this maximum delay. This can help to get smoother velocity prediction. Last velocity computed is used directly if "Odom/FilteringStrategy" is set or the delay is below the odometry rate.]
Param: Odom/Holonomic = "true"                             [If the robot is holonomic (strafing commands can be issued). If not, y value will be estimated from x and yaw values (y=x*tan(yaw)).]
Param: Odom/ImageBufferSize = "1"                          [Data buffer size (0 min inf).]
Param: Odom/ImageDecimation = "1"                          [Decimation of the images before registration. Negative decimation is done from RGB size instead of depth size (if depth is smaller than RGB, it may be interpolated depending of the decimation value).]
Param: Odom/KalmanMeasurementNoise = "0.01"                [Process measurement covariance value.]
Param: Odom/KalmanProcessNoise = "0.001"                   [Process noise covariance value.]
Param: Odom/KeyFrameThr = "0.3"                            [[Visual] Create a new keyframe when the number of inliers drops under this ratio of features in last frame. Setting the value to 0 means that a keyframe is created for each processed frame.]
Param: Odom/ParticleLambdaR = "100"                        [Lambda of rotational components (roll,pitch,yaw).]
Param: Odom/ParticleLambdaT = "100"                        [Lambda of translation components (x,y,z).]
Param: Odom/ParticleNoiseR = "0.002"                       [Noise (rad) of rotational components (roll,pitch,yaw).]
Param: Odom/ParticleNoiseT = "0.002"                       [Noise (m) of translation components (x,y,z).]
Param: Odom/ParticleSize = "400"                           [Number of particles of the filter.]
Param: Odom/ResetCountdown = "0"                           [Automatically reset odometry after X consecutive images on which odometry cannot be computed (value=0 disables auto-reset).]
Param: Odom/ScanKeyFrameThr = "0.9"                        [[Geometry] Create a new keyframe when the number of ICP inliers drops under this ratio of points in last frame's scan. Setting the value to 0 means that a keyframe is created for each processed frame.]
Param: Odom/Strategy = "0"                                 [0=Frame-to-Map (F2M) 1=Frame-to-Frame (F2F) 2=Fovis 3=viso2 4=DVO-SLAM 5=ORB_SLAM2 6=OKVIS 7=LOAM 8=MSCKF_VIO 9=VINS-Fusion]
Param: Odom/VisKeyFrameThr = "150"                         [[Visual] Create a new keyframe when the number of inliers drops under this threshold. Setting the value to 0 means that a keyframe is created for each processed frame.]
Param: OdomF2M/BundleAdjustment = "1"                      [Local bundle adjustment: 0=disabled, 1=g2o, 2=cvsba, 3=Ceres.]
Param: OdomF2M/BundleAdjustmentMaxFrames = "10"            [Maximum frames used for bundle adjustment (0=inf or all current frames in the local map).]
Param: OdomF2M/MaxNewFeatures = "0"                        [[Visual] Maximum features (sorted by keypoint response) added to local map from a new key-frame. 0 means no limit.]
Param: OdomF2M/MaxSize = "2000"                            [[Visual] Local map size: If > 0 (example 5000), the odometry will maintain a local map of X maximum words.]
Param: OdomF2M/ScanMaxSize = "2000"                        [[Geometry] Maximum local scan map size.]
Param: OdomF2M/ScanRange = "0"                             [[Geometry] Distance Range used to filter points of local map (when > 0). 0 means local map is updated using time and not range.]
Param: OdomF2M/ScanSubtractAngle = "45"                    [[Geometry] Max angle (degrees) used to filter points of a new added scan to local map (when "OdomF2M/ScanSubtractRadius">0). 0 means any angle.]
Param: OdomF2M/ScanSubtractRadius = "0.05"                 [[Geometry] Radius used to filter points of a new added scan to local map. This could match the voxel size of the scans.]
Param: OdomF2M/ValidDepthRatio = "0.75"                    [If a new frame has points without valid depth, they are added to local feature map only if points with valid depth on total points is over this ratio. Setting to 1 means no points without valid depth are added to local feature map.]
Param: OdomFovis/BucketHeight = "80"                       []
Param: OdomFovis/BucketWidth = "80"                        []
Param: OdomFovis/CliqueInlierThreshold = "0.1"             [See Howard's greedy max-clique algorithm for determining the maximum set of mutually consisten feature matches. This specifies the compatibility threshold, in meters.]
Param: OdomFovis/FastThreshold = "20"                      [FAST threshold.]
Param: OdomFovis/FastThresholdAdaptiveGain = "0.005"       [FAST threshold adaptive gain.]
Param: OdomFovis/FeatureSearchWindow = "25"                [Specifies the size of the search window to apply when searching for feature matches across time frames.  The search is conducted around the feature location predicted by the initial rotation estimate.]
Param: OdomFovis/FeatureWindowSize = "9"                   [The size of the n x n image patch surrounding each feature, used for keypoint matching.]
Param: OdomFovis/InlierMaxReprojectionError = "1.5"        [The maximum image-space reprojection error (in pixels) a feature match is allowed to have and still be considered an inlier in the set of features used for motion estimation.]
Param: OdomFovis/MaxKeypointsPerBucket = "25"              []
Param: OdomFovis/MaxMeanReprojectionError = "10.0"         [Maximum mean reprojection error over the inlier feature matches for the motion estimate to be considered valid.]
Param: OdomFovis/MaxPyramidLevel = "3"                     [The maximum Gaussian pyramid level to process the image at. Pyramid level 1 corresponds to the original image.]
Param: OdomFovis/MinFeaturesForEstimate = "20"             [Minimum number of features in the inlier set for the motion estimate to be considered valid.]
Param: OdomFovis/MinPyramidLevel = "0"                     [The minimum pyramid level.]
Param: OdomFovis/StereoMaxDisparity = "128"                []
Param: OdomFovis/StereoMaxDistEpipolarLine = "1.5"         []
Param: OdomFovis/StereoMaxRefinementDisplacement = "1.0"   []
Param: OdomFovis/StereoRequireMutualMatch = "true"         []
Param: OdomFovis/TargetPixelsPerFeature = "250"            [Specifies the desired feature density as a ratio of input image pixels per feature detected.  This number is used to control the adaptive feature thresholding.]
Param: OdomFovis/UpdateTargetFeaturesWithRefined = "false" [When subpixel refinement is enabled, the refined feature locations can be saved over the original feature locations.  This has a slightly negative impact on frame-to-frame visual odometry, but is likely better when using this library as part of a visual SLAM algorithm.]
Param: OdomFovis/UseAdaptiveThreshold = "true"             [Use FAST adaptive threshold.]
Param: OdomFovis/UseBucketing = "true"                     []
Param: OdomFovis/UseHomographyInitialization = "true"      [Use homography initialization.]
Param: OdomFovis/UseImageNormalization = "false"           []
Param: OdomFovis/UseSubpixelRefinement = "true"            [Specifies whether or not to refine feature matches to subpixel resolution.]
Param: OdomLOAM/AngVar = "0.01"                            [Angular output variance.]
Param: OdomLOAM/LinVar = "0.01"                            [Linear output variance.]
Param: OdomLOAM/LocalMapping = "true"                      [Local mapping. It adds more time to compute odometry, but accuracy is significantly improved.]
Param: OdomLOAM/ScanPeriod = "0.1"                         [Scan period (s)]
Param: OdomLOAM/Sensor = "2"                               [Velodyne sensor: 0=VLP-16, 1=HDL-32, 2=HDL-64E]
Param: OdomMSCKF/FastThreshold = "10"                      []
Param: OdomMSCKF/GridCol = "5"                             []
Param: OdomMSCKF/GridMaxFeatureNum = "4"                   []
Param: OdomMSCKF/GridMinFeatureNum = "3"                   []
Param: OdomMSCKF/GridRow = "4"                             []
Param: OdomMSCKF/InitCovAccBias = "0.01"                   []
Param: OdomMSCKF/InitCovExRot = "0.00030462"               []
Param: OdomMSCKF/InitCovExTrans = "0.000025"               []
Param: OdomMSCKF/InitCovGyroBias = "0.01"                  []
Param: OdomMSCKF/InitCovVel = "0.25"                       []
Param: OdomMSCKF/MaxCamStateSize = "20"                    []
Param: OdomMSCKF/MaxIteration = "30"                       []
Param: OdomMSCKF/NoiseAcc = "0.05"                         []
Param: OdomMSCKF/NoiseAccBias = "0.01"                     []
Param: OdomMSCKF/NoiseFeature = "0.035"                    []
Param: OdomMSCKF/NoiseGyro = "0.005"                       []
Param: OdomMSCKF/NoiseGyroBias = "0.001"                   []
Param: OdomMSCKF/OptTranslationThreshold = "0"             []
Param: OdomMSCKF/PatchSize = "15"                          []
Param: OdomMSCKF/PositionStdThreshold = "8.0"              []
Param: OdomMSCKF/PyramidLevels = "3"                       []
Param: OdomMSCKF/RansacThreshold = "3"                     []
Param: OdomMSCKF/RotationThreshold = "0.2618"              []
Param: OdomMSCKF/StereoThreshold = "5"                     []
Param: OdomMSCKF/TrackPrecision = "0.01"                   []
Param: OdomMSCKF/TrackingRateThreshold = "0.5"             []
Param: OdomMSCKF/TranslationThreshold = "0.4"              []
Param: OdomMono/InitMinFlow = "100"                        [Minimum optical flow required for the initialization step.]
Param: OdomMono/InitMinTranslation = "0.1"                 [Minimum translation required for the initialization step.]
Param: OdomMono/MaxVariance = "0.01"                       [Maximum variance to add new points to local map.]
Param: OdomMono/MinTranslation = "0.02"                    [Minimum translation to add new points to local map. On initialization, translation x 5 is used as the minimum.]
Param: OdomOKVIS/ConfigPath = ""                           [Path of OKVIS config file.]
Param: OdomORBSLAM2/Bf = "0.076"                           [Fake IR projector baseline (m) used only when stereo is not used.]
Param: OdomORBSLAM2/Fps = "0.0"                            [Camera FPS.]
Param: OdomORBSLAM2/MapSize = "3000"                       [Maximum size of the feature map (0 means infinite).]
Param: OdomORBSLAM2/MaxFeatures = "1000"                   [Maximum ORB features extracted per frame.]
Param: OdomORBSLAM2/ThDepth = "40.0"                       [Close/Far threshold. Baseline times.]
Param: OdomORBSLAM2/VocPath = ""                           [Path to ORB vocabulary (*.txt).]
Param: OdomVINS/ConfigPath = ""                            [Path of VINS config file.]
Param: OdomViso2/BucketHeight = "50"                       [Height of bucket.]
Param: OdomViso2/BucketMaxFeatures = "2"                   [Maximal number of features per bucket.]
Param: OdomViso2/BucketWidth = "50"                        [Width of bucket.]
Param: OdomViso2/InlierThreshold = "2.0"                   [Fundamental matrix inlier threshold.]
Param: OdomViso2/MatchBinsize = "50"                       [Matching bin width/height (affects efficiency only).]
Param: OdomViso2/MatchDispTolerance = "2"                  [Disparity tolerance for stereo matches (in pixels).]
Param: OdomViso2/MatchHalfResolution = "true"              [Match at half resolution, refine at full resolution.]
Param: OdomViso2/MatchMultiStage = "true"                  [Multistage matching (denser and faster).]
Param: OdomViso2/MatchNmsN = "3"                           [Non-max-suppression: min. distance between maxima (in pixels).]
Param: OdomViso2/MatchNmsTau = "50"                        [Non-max-suppression: interest point peakiness threshold.]
Param: OdomViso2/MatchOutlierDispTolerance = "5"           [Outlier removal: disparity tolerance (in pixels).]
Param: OdomViso2/MatchOutlierFlowTolerance = "5"           [Outlier removal: flow tolerance (in pixels).]
Param: OdomViso2/MatchRadius = "200"                       [Matching radius (du/dv in pixels).]
Param: OdomViso2/MatchRefinement = "1"                     [Refinement (0=none,1=pixel,2=subpixel).]
Param: OdomViso2/RansacIters = "200"                       [Number of RANSAC iterations.]
Param: OdomViso2/Reweighting = "true"                      [Lower border weights (more robust to calibration errors).]
Param: Optimizer/Epsilon = "0.0"                           [Stop optimizing when the error improvement is less than this value.]
Param: Optimizer/GravitySigma = "0.0"                      [Gravity sigma value (>=0, typically between 0.1 and 0.3). Optimization is done while preserving gravity orientation of the poses. This should be used only with visual/lidar inertial odometry approaches, for which we assume that all odometry poses are aligned with gravity. Set to 0 to disable gravity constraints. Currently supported only with g2o and GTSAM optimization strategies (see Optimizer/Strategy).]
Param: Optimizer/Iterations = "20"                         [Optimization iterations.]
Param: Optimizer/LandmarksIgnored = "false"                [Ignore landmark constraints while optimizing. Currently only g2o and gtsam optimization supports this.]
Param: Optimizer/PriorsIgnored = "true"                    [Ignore prior constraints (global pose or GPS) while optimizing. Currently only g2o and gtsam optimization supports this.]
Param: Optimizer/Robust = "false"                          [Robust graph optimization using Vertigo (only work for g2o and GTSAM optimization strategies). Not compatible with "RGBD/OptimizeMaxError" if enabled.]
Param: Optimizer/Strategy = "1"                            [Graph optimization strategy: 0=TORO, 1=g2o, 2=GTSAM and 3=Ceres.]
Param: Optimizer/VarianceIgnored = "false"                 [Ignore constraints' variance. If checked, identity information matrix is used for each constraint. Otherwise, an information matrix is generated from the variance saved in the links.]
Param: PyMatcher/Cuda = "true"                             [Used by SuperGlue.]
Param: PyMatcher/Iterations = "20"                         [Sinkhorn iterations. Used by SuperGlue.]
Param: PyMatcher/Model = "indoor"                          [For SuperGlue, set only "indoor" or "outdoor". For OANet, set path to one of the pth file (e.g., "OANet/model/gl3d/sift-4000/model_best.pth").]
Param: PyMatcher/Path = ""                                 [Path to python script file (see available ones in rtabmap/corelib/src/pymatcher/*). See the header to see where the script should be copied.]
Param: PyMatcher/Threshold = "0.2"                         [Used by SuperGlue.]
Param: Reg/Force3DoF = "false"                             [Force 3 degrees-of-freedom transform (3Dof: x,y and yaw). Parameters z, roll and pitch will be set to 0.]
Param: Reg/RepeatOnce = "true"                             [Do a second registration with the output of the first registration as guess. Only done if no guess was provided for the first registration (like on loop closure). It can be useful if the registration approach used can use a guess to get better matches.]
Param: Reg/Strategy = "0"                                  [0=Vis, 1=Icp, 2=VisIcp]
Param: Rtabmap/PublishRAMUsage = "false"                   [Publishing RAM usage in statistics (may add a small overhead to get info from the system).]
Param: SIFT/ContrastThreshold = "0.04"                     [The contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector.]
Param: SIFT/EdgeThreshold = "10"                           [The threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are filtered out (more features are retained).]
Param: SIFT/NFeatures = "0"                                [The number of best features to retain. The features are ranked by their scores (measured in SIFT algorithm as the local contrast).]
Param: SIFT/NOctaveLayers = "3"                            [The number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution.]
Param: SIFT/RootSIFT = "false"                             [Apply RootSIFT normalization of the descriptors.]
Param: SIFT/Sigma = "1.6"                                  [The sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.]
Param: SURF/Extended = "false"                             [Extended descriptor flag (true - use extended 128-element descriptors; false - use 64-element descriptors).]
Param: SURF/GpuKeypointsRatio = "0.01"                     [Used with SURF GPU.]
Param: SURF/GpuVersion = "false"                           [GPU-SURF: Use GPU version of SURF. This option is enabled only if OpenCV is built with CUDA and GPUs are detected.]
Param: SURF/HessianThreshold = "500"                       [Threshold for hessian keypoint detector used in SURF.]
Param: SURF/OctaveLayers = "2"                             [Number of octave layers within each octave.]
Param: SURF/Octaves = "4"                                  [Number of pyramid octaves the keypoint detector will use.]
Param: SURF/Upright = "false"                              [Up-right or rotated features flag (true - do not compute orientation of features; false - compute orientation).]
Param: SuperPoint/Cuda = "true"                            [Use Cuda device for Torch, otherwise CPU device is used by default.]
Param: SuperPoint/ModelPath = ""                           [[Required] Path to pre-trained weights Torch file of SuperPoint (*.pt).]
Param: SuperPoint/NMS = "true"                             [If true, non-maximum suppression is applied to detected keypoints.]
Param: SuperPoint/NMSRadius = "4"                          [[SuperPoint/NMS=true] Minimum distance (pixels) between keypoints.]
Param: SuperPoint/Threshold = "0.010"                      [Detector response threshold to accept keypoint.]
Param: Vis/BundleAdjustment = "1"                          [Optimization with bundle adjustment: 0=disabled, 1=g2o, 2=cvsba, 3=Ceres.]
Param: Vis/CorFlowEps = "0.01"                             [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorFlowIterations = "30"                        [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorFlowMaxLevel = "3"                           [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorFlowWinSize = "16"                           [[Vis/CorType=1] See cv::calcOpticalFlowPyrLK(). Used for optical flow approach.]
Param: Vis/CorGuessMatchToProjection = "false"             [[Vis/CorType=0] Match frame's corners to source's projected points (when guess transform is provided) instead of projected points to frame's corners.]
Param: Vis/CorGuessWinSize = "20"                          [[Vis/CorType=0] Matching window size (pixels) around projected points when a guess transform is provided to find correspondences. 0 means disabled.]
Param: Vis/CorNNDR = "0.8"                                 [[Vis/CorType=0] NNDR: nearest neighbor distance ratio. Used for knn features matching approach.]
Param: Vis/CorNNType = "1"                                 [[Vis/CorType=0] kNNFlannNaive=0, kNNFlannKdTree=1, kNNFlannLSH=2, kNNBruteForce=3, kNNBruteForceGPU=4, BruteForceCrossCheck=5, SuperGlue=6, GMS=7. Used for features matching approach.]
Param: Vis/CorType = "0"                                   [Correspondences computation approach: 0=Features Matching, 1=Optical Flow]
Param: Vis/DepthAsMask = "true"                            [Use depth image as mask when extracting features.]
Param: Vis/EpipolarGeometryVar = "0.1"                     [[Vis/EstimationType = 2] Epipolar geometry maximum variance to accept the transformation.]
Param: Vis/EstimationType = "1"                            [Motion estimation approach: 0:3D->3D, 1:3D->2D (PnP), 2:2D->2D (Epipolar Geometry)]
Param: Vis/FeatureType = "8"                               [0=SURF 1=SIFT 2=ORB 3=FAST/FREAK 4=FAST/BRIEF 5=GFTT/FREAK 6=GFTT/BRIEF 7=BRISK 8=GFTT/ORB 9=KAZE 10=ORB-OCTREE 11=SuperPoint 12=SURF/FREAK 13=GFTT/DAISY 14=SURF/DAISY]
Param: Vis/ForwardEstOnly = "true"                         [Forward estimation only (A->B). If false, a transformation is also computed in backward direction (B->A), then the two resulting transforms are merged (middle interpolation between the transforms).]
Param: Vis/GridCols = "1"                                  [Number of columns of the grid used to extract uniformly "Vis/MaxFeatures / grid cells" features from each cell.]
Param: Vis/GridRows = "1"                                  [Number of rows of the grid used to extract uniformly "Vis/MaxFeatures / grid cells" features from each cell.]
Param: Vis/InlierDistance = "0.1"                          [[Vis/EstimationType = 0] Maximum distance for feature correspondences. Used by 3D->3D estimation approach.]
Param: Vis/Iterations = "300"                              [Maximum iterations to compute the transform.]
Param: Vis/MaxDepth = "0"                                  [Max depth of the features (0 means no limit).]
Param: Vis/MaxFeatures = "1000"                            [0 no limits.]
Param: Vis/MeanInliersDistance = "0.0"                     [Maximum distance (m) of the mean distance of inliers from the camera to accept the transformation. 0 means disabled.]
Param: Vis/MinDepth = "0"                                  [Min depth of the features (0 means no limit).]
Param: Vis/MinInliers = "20"                               [Minimum feature correspondences to compute/accept the transformation.]
Param: Vis/MinInliersDistribution = "0.0"                  [Minimum distribution value of the inliers in the image to accept the transformation. The distribution is the second eigen value of the PCA (Principal Component Analysis) on the keypoints of the normalized image [-0.5, 0.5]. The value would be between 0 and 0.5. 0 means disabled.]
Param: Vis/PnPFlags = "0"                                  [[Vis/EstimationType = 1] PnP flags: 0=Iterative, 1=EPNP, 2=P3P]
Param: Vis/PnPRefineIterations = "0"                       [[Vis/EstimationType = 1] Refine iterations. Set to 0 if "Vis/BundleAdjustment" is also used.]
Param: Vis/PnPReprojError = "2"                            [[Vis/EstimationType = 1] PnP reprojection error.]
Param: Vis/RefineIterations = "5"                          [[Vis/EstimationType = 0] Number of iterations used to refine the transformation found by RANSAC. 0 means that the transformation is not refined.]
Param: Vis/RoiRatios = "0.0 0.0 0.0 0.0"                   [Region of interest ratios [left, righ